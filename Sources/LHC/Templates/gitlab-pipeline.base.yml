#{#
# This is a template for dynamically generating a Gitlab pipeline configuration for a release train and channel.
# It is meant to be used alongside the fastlane template to create dynamic pipelines for each train, according to git
# history and the .lhc configuration file.
#}{% if true %}
# This file is automatically generated. Do not edit it.
#{% endif %}

workflow:
  name: {% block name %}"{{ config.build.productName }} {{ config.build.platform }} {{ release.versionString }} ($TIMESTAMP)"{% endblock %}
  rules:
    - if: $CI_PIPELINE_SOURCE == "parent_pipeline"

default:
  image: {% block image %}"{{ config.build.platform }}-{{ config.build.productName }}"{% endblock %}

variables:
{% block variables %}
  ARTIFACTS_DIR: "$JOBS_OUTPUT_PATH/{{ config.name }}/$CONFIGURATION"
  # Use parallel compression/decompression to speed up caching
  FF_USE_FASTZIP: {% block use_fastzip %}"true"{% endblock %}
  ARTIFACT_COMPRESSION_LEVEL: {% block artifact_compression_level %}"fast"{% endblock %}
  # We don't care about size of the caches since they're stored locally, just the time spent to zip/unzip them
  CACHE_COMPRESSION_LEVEL: {% block cache_compression_level %}"fastest"{% endblock %}
  # Increase the timeout for resolving build settings
  FASTLANE_XCODEBUILD_SETTINGS_TIMEOUT: {% block xcodebuild_settings_timeout %}300{% endblock %}
  # Unique timestamp according to the commit and pipeline ID
  TIMESTAMP: {% block timestamp %}"{% include "timestamp.base" %}"{% endblock %}
{% endblock %}
{% if config.distribution.sparkle %}
{% block sparkle_variables %}
  SPARKLE_XML_FILE: "sparkle.xml"
  APPCAST_URL: "https://protonvpn.com/download/macos-update3.xml"
{% endif %}
{% endif %}

stages:
{% block stages %}
  - {% block build_stage %}build{% endblock %}
  - {% block publish_stage %}publish{% endblock %}
  - {% block unit_test_stage %}test{% endblock %}
  - {% block environment_deploy_stage %}deploy{% endblock %}
  - {% block ui_test_stage %}test_ui{% endblock %}
  - {% block cleanup_stage %}cleanup{% endblock %}
{% endblock %}

# Require the artifacts from the describe job.
.child_pipeline:
  needs: &child_pipeline_needs
    - pipeline: $PARENT_PIPELINE_ID
      job: 'prepare'

##
## ---- Includes
##
{% block include %}
{% endblock %}

##
## ---- Job templates
##

{% block templates %}
# Copy the templated fastlane directory for the train into pwd - generated by the describe job.
# See: Integration/Templates/fastlane
.copy_fastlane:
  script: &copy_fastlane_script
    {% if release.tagName %}
    - cp -r $DESCRIBE_DIR/release/fastlane .
    {% else %}
    - cp -r $DESCRIBE_DIR/{{ config.name }}/fastlane .
    {% endif %}

  # If .profile modifies $PATH in any way, we want to be able to use it.
# This is specifically to get the `sign_update` command to work, because it's installed in a non-standard location.
.source_profile:
  script: &source_profile_script
    - |
      if [ -f "$HOME/.profile" ]; then
        echo "Found .profile, sourcing contents..."
        source "$HOME/.profile"
      fi

# Common output paths for all fastlane jobs.
.fastlane_build_vars:
  script: &fastlane_build_vars_script
    - |
      FASTLANE_ARGS+=("result_bundle:true")
      # We don't want CI to automatically update packages for us
      FASTLANE_ARGS+=("disable_package_automatic_updates:true")
      FASTLANE_ARGS+=("result_bundle_path:${ARTIFACTS_DIR}")
      FASTLANE_ARGS+=("output_directory:${ARTIFACTS_DIR}")
      FASTLANE_ARGS+=("buildlog_path:${ARTIFACTS_DIR}")
      FASTLANE_ARGS+=("derived_data_path:$DERIVED_DATA_PATH")

# Main job template
.job_template:
  extends:
    {% block job_template_extends %}
    {% endblock %}

# Job template for all test runs
.test_template:
  extends:
    - .job_template
    - .build_caches
  variables:
    {% block test_variables %}
    CONFIGURATION: Debug
    DERIVED_DATA_CACHE_POLICY: pull
    SPM_CACHE_POLICY: pull
    {% endblock %}
  tags:
    {% block test_tags %}
    {% endblock %}
  script:
    - *copy_fastlane_script
    - FASTLANE_ARGS=("skip_build:true" "test_without_building:true" "build_products_dir:${DERIVED_DATA_PATH}/Build/Products")
    - FASTLANE_ARGS+=("testplan:{{ config.build.productName }}-{{ config.build.platform|lowercase }}-$TEST_CASES")
    - FASTLANE_ARGS+=("skip_package_dependencies_resolution:true")
    - *fastlane_build_vars_script
    - fastlane testit "${FASTLANE_ARGS[@]}"
  needs: &test_template_needs
    - *child_pipeline_needs
    {% block test_dependencies %}
    - job: "build:{{ config.name }}"
      parallel:
        matrix:
          - TARGET: tests
            CONFIGURATION: Debug
    {% endblock %}
  artifacts:
    name: "{{ config.name }}-tests-failure-$CI_COMMIT_SHORT_SHA"
    when: on_failure
    paths:
      - output/
    expire_in: {% block test_results_expiry %}5 days{% endblock %}
    # Quoting Gitlab documentation: "The artifacts created for artifacts:reports are always
    # uploaded, regardless of the job results (success or failure)."
    reports:
      coverage_report:
        coverage_format: cobertura
        path: "$ARTIFACTS_DIR/cobertura.xml"
      junit:
        - "$ARTIFACTS_DIR/report.junit"
##
## ---- Cache setup for DerivedData, SPM packages, and Mint build dependencies
##
{% block cache_templates %}
.derived_data_cache:
  variables: &derived_data_cache_variables
    DERIVED_DATA_PATH: .caches/Xcode/DerivedData
    DERIVED_DATA_CACHE_POLICY: pull-push
  cache: &derived_data_cache_cache
    - key: build-{{ config.build.platform }}-$CI_COMMIT_REF_SLUG
      fallback_keys:
        - build-{{ config.build.platform }}-$CI_DEFAULT_BRANCH
      paths:
        - $DERIVED_DATA_PATH
      policy: $DERIVED_DATA_CACHE_POLICY

.mint_cache:
  variables: &mint_cache_variables
    MINT_PATH: .caches/mint
    MINT_LINK_PATH: $MINT_PATH/bin
    MINT_CACHE_POLICY: pull-push
  cache: &mint_cache_cache
    - key: mint-$CI_COMMIT_REF_SLUG
      fallback_keys:
        - mint-$CI_DEFAULT_BRANCH
      paths:
        - $MINT_CACHE_PATH
      policy: $MINT_CACHE_POLICY

.build_caches:
  variables: &test_job_caches_variables
    <<: *derived_data_cache_variables
    <<: *mint_cache_variables
  cache: &test_job_caches_cache
    - *derived_data_cache_cache
    - *mint_cache_cache
{% endblock %}

# TODO: This explicitly names 'external' as a location for containing external dependencies, this should
# be parameterized or broken out into the file that depends on it.
.restore_mtimes:
  # Restore the mtimes of all local source files, including submodules and SPM dependencies.
  # This is so that Xcode knows which files were changed since the last build, so it can most effectively use the
  # DerivedData cache.
  script: &restore_mtimes_script
    - |
      git restore-mtime --force

      pushd "external"
      for submodule in $(ls); do
          pushd "$submodule"
          echo "Updating mtimes for $submodule..."
          git restore-mtime --force
          popd
      done
      popd

      CHECKOUTS="$DERIVED_DATA_PATH/SourcePackages/checkouts"
      if [ -d "$CHECKOUTS" ]; then
          pushd "$CHECKOUTS"
          for dependency in $(ls); do
              pushd "$dependency"
              echo "Updating mtimes for $dependency..."
              git restore-mtime --force
              popd
          done
          popd
      fi
{% endblock %}

##
## ---- Building artifacts
##

{% block build_job %}
build:{{ config.name }}:
  extends:
    - .job_template
    - .build_caches
  stage: {{ block.build_stage }}
  tags:
    {% block build_tags %}
    {% endblock %}
  script: 
    - *copy_fastlane_script
    - FASTLANE_ARGS=("configuration:${CONFIGURATION}")
    - *fastlane_build_vars_script
    - *restore_mtimes_script
    - |
      case "$TARGET" in
        app) fastlane buildit "${FASTLANE_ARGS[@]}" ;;
        tests) fastlane testit build_for_testing:true "${FASTLANE_ARGS[@]}" ;;
        *) exit 1 ;;
      esac
  {% block build_matrix %}
  # New tag, build release and staging app, along with tests
  parallel:
    matrix:
      - TARGET: app
        CONFIGURATION: [{% for c in config.build.configurations %}{{ c }}{% if not forloop.last %}, {% endif %}{% endfor %}]
      - TARGET: tests
        CONFIGURATION: Debug
  {% endblock %}
  needs:
    - pipeline: $PARENT_PIPELINE_ID
      job: 'prepare'
  artifacts:
    name: "{{ config.name }}-$ci_commit_ref_slug"
    when: always
    paths:
      - ${JOBS_OUTPUT_PATH}/{{ config.name }}/*
    expire_in: {% block build_expiry %}7 days{% endblock %}
{% endblock %}

##
## ---- Running tests
##

{% block unit_test_job %}
# Unit tests, run everywhere
test:{{ config.name }}:unit:
  extends:
    - .test_template
  stage: {{ block.unit_test_stage }}
  variables:
    TEST_CASES: {% block unit_test_cases %}Unit-All{% endblock %}
{% endblock %}

{% block ui_test_job %}
test:{{ config.name }}:ui:all:
  variables:
    TEST_CASES: UI-All
{% else %}
test:{{ config.name }}:ui:smoke:
  variables:
    TEST_CASES: UI-Smoke
{% endif %}
  stage: {{ block.ui_test_stage }}
  extends:
    - .test_template
  needs:
    - *test_template_needs
    - job: 'deploy:review' # Make sure env gets deployed before starting UI tests
{% endblock %}

##
## ---- Publishing a new release
##

{% block publish_job %}
publish:{{ config.name }}:app:
  variables:
    GIT_SUBMODULE_STRATEGY: none
    GIT_DEPTH: 1
  tags:
    {% block publish_tags %}
    {% endblock %}
  extends: 
    - .mint_cache
  script:
    - *source_profile_script
    - *copy_fastlane_script
    - |
      for CONFIGURATION in Release Staging; do
          echo "Publishing $config app build."
          ARTIFACTS_DIR="$JOBS_OUTPUT_PATH/{{ config.name }}/$CONFIGURATION"
          FASTLANE_ARGS=("configuration:$config" "output_directory:${ARTIFACTS_DIR}")
          fastlane shipit "${FASTLANE_ARGS[@]}"
      done
  needs:
    - *child_pipeline_needs
    {% block publish_dependencies %}
    {% for c in config.build.configurations %}
    # For alpha builds, we need access to the jobs that created the binaries.
    - job: 'build:{{ config.name }}'
      parallel:
        matrix:
          - TARGET: app
            CONFIGURATION: {{ c }}
    {% endfor %}
  environment:
    name: {{ channel }}
    url: "$CI_PAGES_URL/$CI_COMMIT_REF_SLUG/documentation/protonvpnrelease/"
{% endblock %}

{% block announce_job %}
cleanup:announce:tag:
  variables:
    GIT_SUBMODULE_STRATEGY: none
    GIT_DEPTH: 1
  stage: {{ block.cleanup_stage }}
  tags:
    - vpn-apple-xs-new
    - ci-vilnius-1
  extends:
    - .job_template
    - .mint_cache
  script: 
    - *copy_fastlane_script
    - fastlane shoutit "slack_filename:$DESCRIBE_DIR/release/slack-message.txt"
{% if not target|attrs:config.trailers.releasePipelineTrailer %}
    - git fetch origin '+refs/notes/*:refs/notes/*'
    - mint run git-lhc attr add '{{ config.trailers.releasePipelineTrailer }}={{ config.build.ci.pipelineId }}'
    - git push origin 'refs/notes/*'
{% endif %}
  needs:
    - *child_pipeline_needs
    - job: pages
    - job: "build:{{ config.name }}:all"
      parallel:
        matrix:
         - TARGET: app
           CONFIGURATION: {{ configuration }}
    {% if train == "macOS" %}
    {% if channel == "alpha" or channel == "releaseCandidate" %} # Alpha and RC are for release candidates
    - job: artifactlift-release-candidate-artifacts
    # artifactlift job (to make sure the binary has been uploaded)
    {% else %}
    - job: artifactlift-release-artifacts
    - job: artifactlift-release-metadata
    {% endif %}
    {% endif %}
{% endblock %}

# NB: This job *must* be called pages in order for the site to work.
pages:
  stage: {{ block.publish_stage }}
  extends:
    - .publish_template
    - .child_pipeline
  variables:
    GIT_SUBMODULE_STRATEGY: none
    GIT_DEPTH: 1
{% if release.tagName %}
    BASE_PATH: $CI_COMMIT_REF_SLUG
    DOCC_PATH: "$DESCRIBE_DIR/release/pages.docc"
{% else %}
    BASE_PATH: "$CI_COMMIT_REF_SLUG/{{ config.name }}"
    DOCC_PATH: "$DESCRIBE_DIR/{{ config.name }}/pages.docc"
{% endif %}
  script:
    - echo "$CI_PAGES_URL/$BASE_PATH/documentation/protonvpnrelease"
    - |
      # hack to get the path component of the URL, so we can tell the doc generation what the base path is
      # (use CI_PAGES_DOMAIN as the delimiter of a URL like https://subdomain.pages-host.com/page/base/path;
      # since CI_PAGES_DOMAIN is pages-host.com, then the "second field" of the string is /page/base/path,
      # and then the sed command strips the leading slash)
      PROJECT_PATH=$(awk -F "$CI_PAGES_DOMAIN" '{print $2}' <<< "$CI_PAGES_URL" | sed 's/^\///')
      mkdir -p "public/$BASE_PATH"
      xcrun docc convert --hosting-base-path "${PROJECT_PATH}/$BASE_PATH" --output-path "public/$BASE_PATH" $DOCC_PATH
    {% if config.distribution.sparkle %}{# TODO: need to move this to a separate publish job #}
    - |
      APPCAST_SIGNATURE=$(cat artifacts/sparkle.signature)
      APPCAST_DOWNLOAD_URL="https://proton.me/download/macos/{{ version }}/ProtonVPN_mac_v{{ short_version }}.dmg"

      export APPCAST_SIGNATURE
      export APPCAST_DOWNLOAD_URL

      # Download the Sparkle file, for later consumption by the metadata upload step
      curl --location --output "$SPARKLE_XML_FILE" "$APPCAST_URL"

      # Add signature and download URL to file
      envsubst '${APPCAST_SIGNATURE},${APPCAST_DOWNLOAD_URL}' < "$DESCRIBE_DIR/release/sparkle-item.xml" | tee sparkle-item.xml

      # Indent each line in the item file
      sed -i.bak 's/^/        /g' sparkle-item.xml

      # Insert new item into appcast
      # INSERTION_POINT='\<\!\-\- \>8 Next release \>8 \-\-\>'
      INSERTION_POINT='\<language\>en\<\/language\>'
      sed "/$INSERTION_POINT/r sparkle-item.xml" "$SPARKLE_XML_FILE" > "public/$SPARKLE_XML_FILE"
    {% endif %}
  # prevent us from downloading previous build artifacts, we just need the pages
  needs:
    # For the pages template (and sparkle template if needed)
    - *child_pipeline_needs
    {% if train == "macOS" and channel != "alpha" %}
    # For sparkle.signature
    - job: 'artifactlift-release-artifacts'
    {% endif %}
  artifacts:
{% if release.tagName %}
    name: "$CI_COMMIT_REF_SLUG"
    expire_in: never
{% else %}
    name: "{{ config.name }}-$CI_COMMIT_REF_SLUG"
    expire_in: 7 days
{% endif %}
    paths:
      - artifacts/sparkle.xml
{% if not release.tagName %} # Only build pages in MR pipelines if the template files have changed
  rules:
    - if: $CI_PIPELINE_SOURCE == "parent_pipeline"
      changes:
        paths:
          - Integration/Templates/pages.docc/*
        compare_to: refs/heads/$CI_DEFAULT_BRANCH
{% endif %}
{% endblock %}

{% block failure_job %}
cleanup:failure:{{ config.name }}:
  stage: {{ cleanup_stage }}
  tags:
    - vpn-apple-xs-new
    - ci-vilnius-1
  variables:
    GIT_SUBMODULE_STRATEGY: none
    GIT_DEPTH: 1
  extends:
    - .job_template
    - .mint_cache
  dependencies: []
  script: 
    - |
      ATTR_ARGS=("{{ config.trailers.failedPipeline }}=$PARENT_PIPELINE_ID")

      # If this pipeline is specifically for a tag, then make sure the attribute is added to the tag object if possible,
      # instead of the commit that the tag is pointing to.
      if [ -n "$CI_COMMIT_TAG" ]; then
          ATTR_ARGS+=("$CI_COMMIT_TAG")
      fi

      git fetch origin '+refs/notes/*:refs/notes/*'
      mint run git-lhc attr add "${ATTR_ARGS[@]}"
      git push origin 'refs/notes/*'
  when: on_failure
{% endblock %}
